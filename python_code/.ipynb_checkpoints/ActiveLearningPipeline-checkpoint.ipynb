{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/python\n",
    "from __future__ import division\n",
    "'''\n",
    "\n",
    "This file provides an active learning environment for the demo interface.\n",
    "Needs the file 'Topic.xlsx' as input.\n",
    "\n",
    "\n",
    "Description of functionality\n",
    "---\n",
    "\n",
    "data model:\n",
    "    COMMENT KASPAR: I interpreted 'score' as the class of the noun phrase, i.e. 0 or 1.\n",
    "    datapoint = { str(noun phrase) : { 'score': float(controversy score), 'confidence':float(confidence)}}\n",
    "    estimates = l st(datapoint1, .... , datapointN) \n",
    "    labelled  = { str(noun phrase) : { 'label' : 'controversial' OR 'noncontroversial') , 'ip' : str(ip address of user) } }\n",
    "\n",
    "included endpoints:\n",
    "\n",
    "GET /controversial \n",
    "    returns top-10 most and least controversial topics\n",
    "\n",
    "GET /unsure\n",
    "    returns a datapoint to label\n",
    "\n",
    "PUT /unsure\n",
    "    updates model \n",
    "\n",
    "---\n",
    "\n",
    "Controversy is labelled on the noun-phrase (here considered topic) level. \n",
    "Timestamps should be implemented on the backend side. \n",
    "\n",
    "'''\n",
    "import random # while real data lacks\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "# KB: Added modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "# libact classes\n",
    "from libact.base.dataset import Dataset\n",
    "from libact.models import LogisticRegression\n",
    "from libact.query_strategies import UncertaintySampling\n",
    "\n",
    "#from elasticsearch import Elasticsearch\n",
    "\n",
    "#ELASTIC_CREDENTIALS = '#elastic.json'\n",
    "#ELASTIC_INDEX       = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(path_to_file):\n",
    "    '''\n",
    "    Okay, let's load the Excel spreadsheet in which topics, \n",
    "    here understood as noun phrases, are given controversy scores.\n",
    "    '''\n",
    "    data = pd.read_excel(path_to_file, header=None,skiprows=1)\n",
    "    \n",
    "    '''\n",
    "    We need to keep track of the original topic name. This information is needed \n",
    "    when asking the user whether the topic is controversial\n",
    "    '''\n",
    "    \n",
    "    names = list(data.ix[:,0])\n",
    "    \n",
    "    ''' \n",
    "    As features we currently only look at # of 'positive' words (col 3),\n",
    "    # of 'negative' words (col 4), and'intensity' (col 5).\n",
    "\n",
    "    '''\n",
    "    \n",
    "    X = np.asarray(data.ix[:,3:5])\n",
    "\n",
    "    '''\n",
    "    The active learning environment used here (libact) needs a few coded observation.\n",
    "    Otherwise search new data points won't work\n",
    "    Since the existing spreadsheet already ranked topics according to their controversy scores, \n",
    "    I made a best guess, and assigned the first five to class 1 (controversial) and the last five\n",
    "    to class 0 (not controversial)\n",
    "    '''\n",
    "    \n",
    "    y = np.asarray([1,1,1,1,1] + [None]*(X.shape[0]-10)+[0,0,0,0,0])\n",
    "\n",
    "    return X,y,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_model(X,y):\n",
    "    '''\n",
    "    Convert feature matrix and target vector to a format that is \n",
    "    easy to digest for the libact model and searchers\n",
    "    '''\n",
    "    trn_ds = Dataset(X,y)\n",
    "\n",
    "    '''\n",
    "    Define model. We start with a simple Logistic Regression.\n",
    "    More refined models can be implemented later.\n",
    "    There is a possibility to integrate Sklearn classifiers.\n",
    "    '''\n",
    "    model=LogisticRegression()\n",
    "\n",
    "    '''\n",
    "    Before looking for new datapoins the model needs to fitted using\n",
    "    the scarce observation we have given, see the construction of the 'y'\n",
    "    target vector in the load_data function\n",
    "    '''\n",
    "    model.train(trn_ds)\n",
    "    return model,trn_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    '''\n",
    "    Function that converts manually given labels to a binary class.\n",
    "    '''\n",
    "    if label == 'controversial':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "X,y,names = load_data('Topics.xlsx')\n",
    "model,trn_ds = initialize_model(X,y)\n",
    "qs = UncertaintySampling(trn_ds, method='lc', model=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unsure(data=None):\n",
    "    '''\n",
    "    implements the /controversial endpoint. \n",
    "\n",
    "    parameters\n",
    "    ----\n",
    "    data: labelled\n",
    "\n",
    "    returns\n",
    "    --- \n",
    "\n",
    "    {\n",
    "        controversial    : estimates,\n",
    "        noncontroversial : estimates\n",
    "\n",
    "    }\n",
    "\n",
    "    CHANGED CODE HERE: We'll use active learning to search for new datapoints.\n",
    "    Two scenarios are possible:\n",
    "    1) If a data point _and_ label are given, it will update the training set and retrain the model.\n",
    "    2) If no data point is given, it will search for a new data point to code and return this.\n",
    "    '''\n",
    "    if data:\n",
    "        ''' expects an object like: {'nounphrase': {'label':'controversial'/'noncrontroversial','ip':'127.0.01'}}'''\n",
    "        # TO DO: CHANGE HERE TO USE JSON AGAIN\n",
    "        data = json.loads(data)\n",
    "        '''get the topic name'''\n",
    "        name = data.keys()[0]\n",
    "        '''get the label'''\n",
    "        label = convert_label(data[name]['label'])\n",
    "        '''get the position of the topic in the training set'''\n",
    "        ask_id = names.index(name)\n",
    "        '''update training set with new label'''\n",
    "        trn_ds.update(ask_id, label)\n",
    "        '''retrain model'''\n",
    "        model.train(trn_ds)\n",
    "        \n",
    "    else:\n",
    "        '''\n",
    "        When asked for a new data point, we call the UncertaintySampling method\n",
    "        and write the name of this topic to JSON file\n",
    "        '''\n",
    "        ask_id = qs.make_query()\n",
    "        results = { 'unsure' : names[ask_id] }\n",
    "        #return results\n",
    "        ## TO DO: commented out JSON endpoints, change this when running the demo\n",
    "        return json.dumps(results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def controversial():\n",
    "    '''\n",
    "    implements the /controversial endpoint. \n",
    "\n",
    "    parameters\n",
    "    ----\n",
    "    none\n",
    "\n",
    "    returns\n",
    "    --- \n",
    "\n",
    "    {\n",
    "        controversial    : estimates,\n",
    "        noncontroversial : estimates\n",
    "    }\n",
    "    \n",
    "    This function returns the ten most controversial and non controversial topic based on the current model.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    labeled_features = trn_ds.get_labeled_entries()\n",
    "    positions = [i for i,a in enumerate(trn_ds.data) if trn_ds.data[i][1] != None]\n",
    "    datapoints = {\n",
    "            names[p]:{\n",
    "                    'score':model.predict(X[p])[0],\n",
    "                    # Get confidence for class one, i.e. the topic being controversial\n",
    "                    'confidence':model.predict_real(X[p])[0][1]\n",
    "                        } for p in positions\n",
    "                }\n",
    "    datapoints_sorted = sorted(datapoints.keys(), key=lambda x: (datapoints[x]['confidence']),reverse=True)\n",
    "    controversial    = datapoints_sorted[:10]\n",
    "    noncontroversial = datapoints_sorted[-10:]\n",
    "    ## return {'controversial':controversial, 'noncontroversial':noncontroversial}\n",
    "    ## TO DO: commented out JSON endpoints, change this when running the demo\n",
    "    return json.dumps(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotating the data point {'unsure': u'thanks/NNS'} as controversial\n",
      "Annotating the data point {'unsure': u'these/DT things/NNS'} as noncontroversial\n",
      "Annotating the data point {'unsure': u'Grandma/NNP'} as noncontroversial\n",
      "Annotating the data point {'unsure': u'the/DT original/JJ source/NN'} as controversial\n",
      "Annotating the data point {'unsure': u'every/DT'} as noncontroversial\n",
      "Annotating the data point {'unsure': u'a/DT claim/NN'} as noncontroversial\n",
      "Annotating the data point {'unsure': u'Japan/NNP'} as noncontroversial\n",
      "Annotating the data point {'unsure': u'Infectious/NNP Diseases/NNP'} as controversial\n",
      "Annotating the data point {'unsure': u'Measles/NNS outbreaks/NNS'} as controversial\n",
      "Annotating the data point {'unsure': u'the/DT public/JJ health/NN system/NN'} as controversial\n",
      "\n",
      "\n",
      "-----controversial topics-----\n",
      "children/NNS\n",
      "vaccines/NNS\n",
      "the/DT unvaccinated/JJ\n",
      "deaths/NNS\n",
      "able/JJ\n",
      "thanks/NNS\n",
      "the/DT original/JJ source/NN\n",
      "Infectious/NNP Diseases/NNP\n",
      "Measles/NNS outbreaks/NNS\n",
      "a/DT claim/NN\n",
      "\n",
      "\n",
      "-----noncontroversial topics-----\n",
      "the/DT public/JJ health/NN system/NN\n",
      "every/DT\n",
      "Grandma/NNP\n",
      "these/DT things/NNS\n",
      "Japan/NNP\n",
      "a/DT look/NN\n",
      "documents/NNS the/DT fact/NN\n",
      "the/DT team/NN\n",
      "an/DT example/NN\n",
      "Davis/NNP RM/NNP\n"
     ]
    }
   ],
   "source": [
    "# Cell used for simulation, we randomly annotate words as being controversial or not \n",
    "# During each iteration we update the model.\n",
    "# Lastly we call the 'controversial' function and sort all topics as controversial\n",
    "# or not based on the confidence score returned by the logistic regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_turns = 10\n",
    "answers = ['noncontroversial','controversial']*int(n_turns/2)\n",
    "random.shuffle(answers)\n",
    "for t in range(n_turns):\n",
    "    result = unsure()\n",
    "    print(u'Annotating the data point {} as {}'.format(result,answers[t]))\n",
    "    labeled = {result['unsure']:{'label':answers[t],'ip':'127.0.01'}}\n",
    "    unsure(labeled)\n",
    "    \n",
    "print('\\n')\n",
    "controversies = controversial()\n",
    "print('-----controversial topics-----')\n",
    "print('\\n'.join(controversies['controversial']))\n",
    "print('\\n')\n",
    "print('-----noncontroversial topics-----')\n",
    "print('\\n'.join(controversies['noncontroversial']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
